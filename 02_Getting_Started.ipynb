{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6649af-b001-4982-a0f0-846c5141146f",
   "metadata": {},
   "source": [
    "# 02_Getting_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fc7126-22f6-4393-b2ed-e6acde045428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b8cdf0-0d57-49d9-952d-97c5f8e7e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the ways to get your API key. My preferred method.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d3dce-af80-4ea4-9142-86d4fb17b045",
   "metadata": {},
   "source": [
    "## First Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660c9e41-e01a-4e6d-88ab-8351aafab2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Davinci model is deprecated\n",
    "# openai.Completion.create(\n",
    "#     model=\"text-davinci-003\",\n",
    "#     prompt=\"How do you say hello in french?\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ec3628-8115-4ec0-8c1e-5fb606bb9e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935uizowA2pHwMaJ9WkCV6izL7YK4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' \"Ring-ding-ding-ding-dingeringeding! Wa-pa-pa-pa-pa-pa-pow!\"', role='assistant', function_call=None, tool_calls=None))], created=1710524744, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=27, prompt_tokens=10, total_tokens=37))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"The fox says\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870baca-65df-4568-9c83-7b3442a1d326",
   "metadata": {},
   "source": [
    "## Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12789862-e712-45f5-8921-e9234f4d3afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935ujinDc4aZQvkY8F9tY6uKSWcp3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. Tokyo, Japan\\n2. Delhi, India\\n3. Shanghai, China\\n4. Sao Paulo, Brazil\\n5. Mumbai, India\\n6. Mexico City, Mexico\\n7. Beijing, China\\n8. Osaka, Japan\\n9. Cairo, Egypt\\n10. New York City, United States\\n11. Dhaka, Bangladesh\\n12. Karachi, Pakistan\\n13. Chongqing, China\\n14. Istanbul, Turkey\\n15. Buenos Aires, Argentina\\n16. Kolkata, India\\n17. Manila, Philippines\\n18. Lagos, Nigeria\\n19. Rio de Janeiro, Brazil\\n20. Istanbul, Turkey', role='assistant', function_call=None, tool_calls=None))], created=1710524745, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=130, prompt_tokens=17, total_tokens=147))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_tokens dfault should be 16, but seems to be more than that.\n",
    "openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"The top 20 most populated cities are: \"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61ed0f3-d3ec-4e42-9c61-6775321f8d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935umtqf17yLKlFHyEqsDfqJohsXm', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='1. Tokyo, Japan\\n2. Delhi, India\\n3. Shanghai,', role='assistant', function_call=None, tool_calls=None))], created=1710524748, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=16, prompt_tokens=17, total_tokens=33))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But if the max_tokens variable is too low then the output will be clipped.\n",
    "openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"The top 10 most populated cities are: \"}],\n",
    "    max_tokens=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5dc3c-70a6-4806-97c9-aba8776954ac",
   "metadata": {},
   "source": [
    "## Stop Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5ddbb8-1d88-435b-88da-bc0adfd795fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish_reason='stop' means to the AI it was the logical place to stop\n",
    "response = openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Generate a list of the best movies of all time \"}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeaebf82-e6fc-42d0-bc28-fc488babc3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Godfather (1972)\n",
      "2. The Shawshank Redemption (1994)\n",
      "3. Pulp Fiction (1994)\n",
      "4. The Dark Knight (2008)\n",
      "5. Schindler's List (1993)\n",
      "6. The Lord of the Rings: The Return of the King (2003)\n",
      "7. Forrest Gump (1994)\n",
      "8. The Matrix (1999)\n",
      "9. Goodfellas (1990)\n",
      "10. Titanic (1997)\n",
      "11. Fight Club (1999)\n",
      "12. Inception (2010)\n",
      "13. The Silence of the Lambs (1991)\n",
      "14. The Departed (2006)\n",
      "15. The Godfather Part II (1974)\n",
      "16. Casablanca (1942)\n",
      "17. The Avengers (2012)\n",
      "18. Gladiator (2000)\n",
      "19. Rear Window (1954)\n",
      "20. 12 Angry Men (1957)\n"
     ]
    }
   ],
   "source": [
    "# openai>=1\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8081944b-47ef-4334-8341-8a8bf4a172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stop'is a str or array that specifies 1-4 sequences where the API should stop generating further tokens if it encounters\n",
    "# that sequence. The final response will not include the sequence.\n",
    "response = openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Generate a list of the best movies of all time \"}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    stop=\"11.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af025977-62ac-44d4-bcce-87bb73a4a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Godfather (1972)\n",
      "2. The Shawshank Redemption (1994)\n",
      "3. The Dark Knight (2008)\n",
      "4. Schindler's List (1993)\n",
      "5. Pulp Fiction (1994)\n",
      "6. The Lord of the Rings: The Return of the King (2003)\n",
      "7. Casablanca (1942)\n",
      "8. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "9. Forrest Gump (1994)\n",
      "10. Titanic (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# openai>=1\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1bc15d-4d2c-4080-af10-58ca32cfafba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935uuqfVPNM2wcNXUtdDJGGCeGFkt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"My favorite game is hide and seek! I like to hide really well and giggle when people find me. It's so much fun! What's your favorite game?\", role='assistant', function_call=None, tool_calls=None))], created=1710524756, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=34, prompt_tokens=120, total_tokens=154))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AI might continue with the conversation, thinking of where it might lead. Thsi way we guarantee it's only\n",
    "# going to respond with one line at a time.\n",
    "prompt = \"\"\"\n",
    "You are a chatbot that speaks like a toddler.\n",
    "\n",
    "User: Hi, how are you?\n",
    "Chatbot: I'm good\n",
    "User: Tell me about your family\n",
    "Chatbot: I have a mommy and a daddy and a baby sister and two kitties\n",
    "User: What do you do for fun?\n",
    "Chatbot: I like to play with my toys, color, go outside and explore, play with my kitties, read stories, and play games with my family.\n",
    "User: That sounds like fun! What's your favorite game?\n",
    "Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "# openai.Completion.create(\n",
    "#     prompt=prompt, model=\"text-davinci-003\", max_tokens=200, stop=[\"Chatbot:\", \"User:\"]\n",
    "# )\n",
    "openai.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=200,\n",
    "    stop=[\"Chatbot:\", \"User:\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8c840-a2ff-462f-8eca-a624e588b307",
   "metadata": {},
   "source": [
    "## N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47145d8-74a4-4af8-add7-1e2a706aac43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935uvgGE4rIe68fsUA88UtB6yutYS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why did the skeleton go to the party alone? \\n\\nBecause he had no body to go with him!', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='Why did the scarecrow win an award for his outstanding performance? Because he was outstanding in his field...even in death!', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='Why did the skeleton go to the party alone? Because he had no body to go with him!', role='assistant', function_call=None, tool_calls=None))], created=1710524757, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=66, prompt_tokens=13, total_tokens=79))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n is how many different completions for the same prompt I want. Defaults to 1\n",
    "# allows us to work with each result separately\n",
    "openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"tell me a joke about death\"}],\n",
    "    max_tokens=200, # CAREFUL: max_tokens per completion\n",
    "    n=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec0cd4-d6fd-429a-b4d0-c195cd88296e",
   "metadata": {},
   "source": [
    "## Echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393a5c4c-a880-44fa-a2cd-ab204502d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-935uw3Y9jtfgUi6cY7qDKSL2HtCwn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Green', role='assistant', function_call=None, tool_calls=None))], created=1710524758, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=1, prompt_tokens=21, total_tokens=22))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openai.Completion.create(\n",
    "#     model=\"text-davinci-003\",\n",
    "#     prompt=\"In a single word, what is the color of a pickle? \",\n",
    "#     max_tokens=100,\n",
    "#     echo=True,\n",
    "# )\n",
    "\n",
    "# With Chat Completions, OpenAI doesn't permit the echo parameter.\n",
    "openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"In a single word, what is the color of a pickle? \"}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d7e11-a52a-4dbf-a91c-ab5ccf3cdc3a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fe3d0-8fb2-4e05-9c1a-ab9f5e7b7ac4",
   "metadata": {},
   "source": [
    "> Some models only work for the chat API, not the completions one (which we are currently using)\n",
    "- **DALL-E:** generates and edits images\n",
    "- **Whisper:** converts audio to text\n",
    "- **Codex:** understand and generates code\n",
    "- **Moderation:** detects safe and unsensitive text\n",
    "- **GPT-3:** understandsand generates natural language\n",
    "- **GPT-3.5:** set of models that improve upon GPT-3\n",
    "- **GPT-4:** The latest and most advances version of OpenAI's large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82191acc-449c-44db-b21c-8c51cac138bf",
   "metadata": {},
   "source": [
    "## Comparing Model Performance and Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ccd0de-a0d2-4129-ac54-4e2f59fe5a7b",
   "metadata": {},
   "source": [
    "[Current pricing page](https://openai.com/pricing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d308d8-4483-4899-87fa-407c49626765",
   "metadata": {},
   "source": [
    "### GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5091971d-a1b3-48a4-b205-3d0b2ed0de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Godfather (1972)\n",
      "2. The Shawshank Redemption (1994)\n",
      "3. The Dark Knight (2008)\n",
      "4. Schindler's List (1993)\n",
      "5. Pulp Fiction (1994)\n",
      "6. The Lord of the Rings: The Return of the King (2003)\n",
      "7. Casablanca (1942)\n",
      "8. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "9. Forrest Gump (1994)\n",
      "10. Titanic (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openai.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I'm sad.  Make me happy please. \"}],\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=100,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de667b47-b582-43b4-a844-2824dae45a19",
   "metadata": {},
   "source": [
    "### GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1acf4737-4291-4c4e-8e8d-875580b86e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Godfather (1972)\n",
      "2. The Shawshank Redemption (1994)\n",
      "3. The Dark Knight (2008)\n",
      "4. Schindler's List (1993)\n",
      "5. Pulp Fiction (1994)\n",
      "6. The Lord of the Rings: The Return of the King (2003)\n",
      "7. Casablanca (1942)\n",
      "8. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "9. Forrest Gump (1994)\n",
      "10. Titanic (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openai.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I'm sad.  Make me happy please. \"}],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=100,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
